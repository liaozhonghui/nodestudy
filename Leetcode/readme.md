数据结构与算法
1. 实际软件开发中如何使用数据结构和算法
六条经验：
1. 时间，空间复杂度不能和性能简单的划等号
2. 抛开数据规模谈数据结构和算法都是“耍流氓”
3. 结合数据特征和访问方式来选择数据结构
4. 需要区别对待IO密集，内存密集（如字符串比较操作，解决方式：减少数据的读取量，看数据是否在内存中连续存储），和计算密集（使用位运算）
5. 善用语言提供的类，避免重复造轮子
6. 千万不要漫无目的的过渡优化（估算数据规模，性能压力进行估算，在真正优化代码的时候，一定要先做benchmark基准测试）

2. 实战篇- 开源项目、基础架构和中间件中都用了哪些数据结构和算法？
具体分析：
1. redis数据库
 - 字符串
 - 列表 （压缩列表，双向循环链表）单个数据不能超过64个字节，数据个数不能超过512个节点，压缩列表使用一段连续的内存空间
 - 字典 （压缩列表，散列表） hash冲突使用了链表法解决，扩容和缩容使用了渐进式hash策略
 - 集合 （有序数组， 散列表)
 - 有序集合 （压缩链表， 跳表）所有元素大小小于64字节，元素个数要小于128个
 - 如何将数据结构进行持久化到磁盘呢？ rdb和aof进行持久化
   （1. 清除原来的存储格式，使用格式化的方式进行存储，容易保存，2. 保留原来的存储格式存储，容易恢复）

2. 搜索引擎
 - 如果通过少量的代码来实现一个小型的搜索引擎？
 8G 100GB
 - 搜集，分析，索引，查询
 逻辑顺序：负责网页内容抽取，分词，构建临时索引，计算pagerank值。索引，主要通过分析阶段得到的临时索引，构建倒排索引。
 查询，主要负责响应用户的请求根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。
 - 搜集阶段：有向图，搜索引擎使用的是广度优先搜索策略 1. 待爬取网页链接文件links.bin，将网页看做是一个大的字符串，然后字符串匹配算法，在这个大的字符串中，搜索<link>这样一个网页标签，然后顺序读取<link></link>之间的字符串。2. 网页判重文件，bloom_filter.bin 使用布隆过滤器进行过滤，节省内存，定期将布隆过滤器持久化到磁盘中。3.原始网页存储文件，doc_raw.bin文件，一个文件中存储多个网页，限制每个文件大小为1GB即可。4. 网页链接及其对应编号的对应文件doc_id.bin
 - 分析阶段：离线分析， 抽取网页文本信息，分词并创建临时索引， 使用ac自动机查找script option style，将标签中的内容进行连带删除，接着去掉所有HTML标签。 分词并创建临时索引，英文分析，中文分词，使用词库进行匹配。将词库中的单词创建成一个trie树，然后拿网页文本在trie树中进行匹配，然后得到一个单词列表，单词编号跟网页的对应关系保存为临时索引文件temp_index.html，将单词跟编号之间的关系保存为单词编号文件term_id.bin.
 - 索引阶段：构建成倒排索引，使用多路归并排序，在实际软件开发中，可以直接利用MapReduce进行处理, 倒排索引文件，还有记录单词编号在索引文件中的偏移位置的文件。index.bin和term_offset.bin文件
 - 查询阶段：用户搜索功能



